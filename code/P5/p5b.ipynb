{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import matplotlib.pyplot as plt\n",
    "from p5a import ReducingresolutionClass\n",
    "from p5c import eval_resolution"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T13:40:53.253868200Z",
     "start_time": "2024-04-09T13:40:51.552468800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load the images\n",
    "images = [Image.open(f'{i}.jpg') for i in range(1, 11)]\n",
    "reducing = ReducingresolutionClass(n=2)\n",
    "features, labels, end_of_each_image, low_res_images =  reducing.reduce(images)\n",
    "list_features = features\n",
    "features = np.array(features)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_features, train_labels = features[:end_of_each_image[7]], labels[:end_of_each_image[7]]\n",
    "val_features, val_labels = features[end_of_each_image[7]:end_of_each_image[8]], labels[end_of_each_image[7]:end_of_each_image[8]]\n",
    "test_features, test_labels = features[end_of_each_image[8]:], labels[end_of_each_image[8]:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T10:44:52.012577100Z",
     "start_time": "2024-04-09T10:43:58.045005Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from model_resolution import MLP, device\n",
    "model = MLP().to(device)\n",
    "\n",
    "# Define the loss function and the optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Convert the datasets to PyTorch tensors and move them to the appropriate device\n",
    "train_features = torch.tensor(train_features, dtype=torch.float32, requires_grad=True).to(device)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.float32, requires_grad=True).to(device)\n",
    "val_features = torch.tensor(val_features, dtype=torch.float32, requires_grad=True).to(device)\n",
    "val_labels = torch.tensor(val_labels, dtype=torch.float32, requires_grad=True).to(device)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T13:22:00.733962200Z",
     "start_time": "2024-04-09T13:22:00.471746200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Loss: 11442.35546875\n",
      "Epoch 2/100 - Loss: 10745.9326171875\n",
      "Epoch 3/100 - Loss: 10042.49609375\n",
      "Epoch 4/100 - Loss: 9347.54296875\n",
      "Epoch 5/100 - Loss: 8663.595703125\n",
      "Epoch 6/100 - Loss: 7966.0205078125\n",
      "Epoch 7/100 - Loss: 7256.9951171875\n",
      "Epoch 8/100 - Loss: 6543.2666015625\n",
      "Epoch 9/100 - Loss: 5834.6640625\n",
      "Epoch 10/100 - Loss: 5138.53076171875\n",
      "Validation Loss: 3093.09033203125\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store the losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Train the MLP\n",
    "for epoch in range(10):  # 100 epochs\n",
    "    model.train()  # Set the model to training mode\n",
    "    optimizer.zero_grad()  # Reset the gradients\n",
    "    train_outputs = model(train_features)  # Forward pass\n",
    "    loss = criterion(train_outputs, train_labels)  # Compute the loss\n",
    "    loss.backward()  # Backward pass\n",
    "    optimizer.step()  # Update the weights\n",
    "\n",
    "    # Store the training loss\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "    # Print the loss for this epoch\n",
    "    print(f'Epoch {epoch+1}/{100} - Training Loss: {loss.item()}')\n",
    "\n",
    "    # Validate the MLP\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # No need to track the gradients\n",
    "        val_outputs = model(val_features)  # Forward pass\n",
    "        val_loss = criterion(val_outputs, val_labels)  # Compute the loss\n",
    "\n",
    "        # Store the validation loss\n",
    "        val_losses.append(val_loss.item())\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            # Print the validation loss\n",
    "            print(f'Epoch {epoch+1}/{100} - Validation Loss: {val_loss.item()}')\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T09:05:31.628323600Z",
     "start_time": "2024-04-09T09:00:42.820131900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'model_part_b.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T15:44:25.626235600Z",
     "start_time": "2024-04-09T15:44:25.545911700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_10980\\4052113209.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_features = torch.tensor(test_features, dtype=torch.float32, requires_grad=True).to(device)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_10980\\4052113209.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_labels = torch.tensor(test_labels, dtype=torch.float32, requires_grad=True).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 48.44804000854492\n"
     ]
    }
   ],
   "source": [
    "# Convert the test dataset to PyTorch tensors and move them to the appropriate device\n",
    "test_features = torch.tensor(test_features, dtype=torch.float32, requires_grad=True).to(device)\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.float32, requires_grad=True).to(device)\n",
    "# Calculate the error function value for the test dataset\n",
    "model = MLP().to(device)\n",
    "model.load_state_dict(torch.load('model_part_b.pth', map_location=device))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # No need to track the gradients\n",
    "    test_outputs = model(test_features)  # Forward pass\n",
    "    test_loss = criterion(test_outputs, test_labels)  # Compute the loss\n",
    "\n",
    "# Print the test loss\n",
    "print(f'Test Loss: {test_loss.item()}')\n",
    "\n",
    "# Generate high-resolution images\n",
    "high_res_images = []\n",
    "for i in end_of_each_image.keys():\n",
    "    if i > 1:\n",
    "        low_res_image_np = features[end_of_each_image[i-1]:end_of_each_image[i]]\n",
    "    else:\n",
    "        low_res_image_np = features[0:end_of_each_image[1]]# Convert PIL Image to numpy array\n",
    "    low_res_image_tensor = torch.tensor(low_res_image_np, dtype=torch.float32, requires_grad=True).to(device)\n",
    "    high_res_image = model(low_res_image_tensor).cpu().detach().numpy()\n",
    "    high_res_images.append(high_res_image)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T15:49:29.368555300Z",
     "start_time": "2024-04-09T15:45:02.947586500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 - SSIM: 0.06539547853300348, PSNR: 8.642003968432451\n",
      "Image 2 - SSIM: 0.2675556486208231, PSNR: 11.153144572364369\n",
      "Image 3 - SSIM: 0.1785107723494155, PSNR: 12.935236537359977\n",
      "Image 4 - SSIM: 0.08564555237944006, PSNR: 11.029140547952522\n",
      "Image 5 - SSIM: 0.07327564128957158, PSNR: 10.027084870792697\n",
      "Image 6 - SSIM: 0.1612746523768042, PSNR: 10.440442849978439\n",
      "Image 7 - SSIM: 0.05159811357307465, PSNR: 8.124327969466986\n",
      "Image 8 - SSIM: 0.13729326014008453, PSNR: 12.784259049037427\n",
      "Image 9 - SSIM: 0.03649404387448192, PSNR: 10.97273126478477\n",
      "Image 10 - SSIM: 0.23285826969205778, PSNR: 10.875041496713564\n"
     ]
    }
   ],
   "source": [
    "# Compare the high-resolution images with the original images\n",
    "eval_resolution(high_res_images, images)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T15:49:49.420717400Z",
     "start_time": "2024-04-09T15:49:46.856844200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Convert the numpy array to integer type\n",
    "high_res_images_quantized = []\n",
    "for i, (high_res_img, img) in enumerate(zip(high_res_images, images)):\n",
    "    high_res_img = high_res_img.reshape(img.width, img.height, 3).astype(np.uint8)\n",
    "    high_res_image_ = high_res_img.astype(np.uint8)\n",
    "    high_res_images_quantized.append(high_res_image_)\n",
    "\n",
    "# Convert the numpy array to a PIL Image\n",
    "high_res_images_pil = [Image.fromarray(img).convert('RGB') for img in high_res_images_quantized]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T15:49:51.815951800Z",
     "start_time": "2024-04-09T15:49:51.769775Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "\n",
    "for i, high_res_images_pili in enumerate(high_res_images_pil):\n",
    "    high_res_images_pili = high_res_images_pili.rotate(-90, expand=True)\n",
    "    from PIL import ImageOps\n",
    "    high_res_images_pili = ImageOps.mirror(high_res_images_pili)\n",
    "    high_res_images_pili.save(f'{i + 1}_b.jpg')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T22:03:53.452802700Z",
     "start_time": "2024-04-09T22:03:53.352532100Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
